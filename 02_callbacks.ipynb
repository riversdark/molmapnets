{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# callbacks\n",
    "> The callback classes used in network training. Mainly for early stopping techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve\n",
    "from sklearn.metrics import auc as calculate_auc\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helper functions\n",
    "\n",
    "### R2 Score\n",
    "\n",
    "First we define an `r2_score` between two vectors, which is the squared Pearson correlation, and which in turn is calculated as\n",
    "\n",
    "$$r = \\frac{\\sum (x - m_x) (y - m_y)}{\\sqrt{\\sum (x - m_x)^2 (y - m_y)^2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from scipy.stats.stats import pearsonr\n",
    "def r2_score(x,y):\n",
    "    \"Squared Pearson Correlation\"\n",
    "    pcc, _ = pearsonr(x,y)\n",
    "    return pcc**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0, 0, 0, 1, 1, 1, 1])\n",
    "b = np.arange(7)\n",
    "\n",
    "r, _ = pearsonr(a, b)\n",
    "\n",
    "np.testing.assert_almost_equal(r**2, r2_score(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-AUC Score\n",
    "\n",
    "*This part is adapted from the official `scikit-learn` [documentation](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html).*\n",
    "\n",
    "The `precision_recall_curve` computes the precision-recall pairs for different probability thresholds in binary classification tasks. It takes an array of true values, `y_true`, and another array of estimated probabilities calculated using the decision function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\n",
    "true positives and ``fp`` the number of false positives. The precision is\n",
    "intuitively the ability of the classifier not to label as positive a sample\n",
    "that is negative.\n",
    "\n",
    "The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\n",
    "true positives and ``fn`` the number of false negatives. The recall is\n",
    "intuitively the ability of the classifier to find all the positive samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([0, 0, 1, 1])\n",
    "y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
    "precision, recall, thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `calculate_auc` function simply calculates the area under curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_auc(recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def prc_auc_score(y_true, y_score):\n",
    "    \"Precision-Area under curve Score\"\n",
    "    precision, recall, threshold  = precision_recall_curve(y_true, y_score)\n",
    "    auc = calculate_auc(recall, precision)\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prc_auc_score(y_true, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(calculate_auc(recall, precision), prc_auc_score(y_true, y_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Reg_EarlyStoppingAndPerformance(tf.keras.callbacks.Callback):\n",
    "    \"The callback class used in regression problems.\"\n",
    "    def __init__(self, train_data, valid_data, y_scaler, MASK = -1e10, patience=5, criteria = 'val_loss', verbose = 0):\n",
    "        \"\"\"\n",
    "        y_scaler: None, sklearn MinMaxScaler, or StandardScaler\n",
    "        \"\"\"\n",
    "        super(Reg_EarlyStoppingAndPerformance, self).__init__()\n",
    "        \n",
    "        assert criteria in ['val_loss', 'val_r2'], 'not support %s ! only %s' % (criteria, ['val_loss', 'val_r2'])\n",
    "        self.x, self.y  = train_data\n",
    "        self.x_val, self.y_val = valid_data\n",
    "        self.y_scaler = y_scaler\n",
    "        \n",
    "        self.history = {'loss':[],\n",
    "                        'val_loss':[],\n",
    "                        \n",
    "                        'rmse':[],\n",
    "                        'val_rmse':[],\n",
    "                        \n",
    "                        'r2':[],\n",
    "                        'val_r2':[],\n",
    "                        \n",
    "                        'epoch':[]}\n",
    "        self.MASK = MASK\n",
    "        self.patience = patience\n",
    "        # best_weights to store the weights at which the minimum loss occurs.\n",
    "        self.best_weights = None\n",
    "        self.criteria = criteria\n",
    "        self.best_epoch = 0\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def rmse(self, y_true, y_pred, inner_y_true = True):\n",
    "        \n",
    "        if self.y_scaler != None:\n",
    "            if inner_y_true:\n",
    "                y_pred = self.y_scaler.inverse_transform(y_pred)\n",
    "                y_true = self.y_scaler.inverse_transform(y_true)\n",
    "            else:\n",
    "                y_pred = self.y_scaler.inverse_transform(y_pred)\n",
    "       \n",
    "        N_classes = y_pred.shape[1]\n",
    "        rmses = []\n",
    "        for i in range(N_classes):\n",
    "            y_pred_one_class = y_pred[:,i]\n",
    "            y_true_one_class = y_true[:, i]\n",
    "            mask = ~(y_true_one_class == self.MASK)\n",
    "            mse = mean_squared_error(y_true_one_class[mask], y_pred_one_class[mask])\n",
    "            rmse = np.sqrt(mse)\n",
    "            rmses.append(rmse)\n",
    "        return rmses   \n",
    "    \n",
    "    \n",
    "    def r2(self, y_true, y_pred, inner_y_true = True):\n",
    "        if self.y_scaler != None:\n",
    "            if inner_y_true:\n",
    "                y_pred = self.y_scaler.inverse_transform(y_pred)\n",
    "                y_true = self.y_scaler.inverse_transform(y_true)\n",
    "            else:\n",
    "                y_pred = self.y_scaler.inverse_transform(y_pred)\n",
    "                \n",
    "        N_classes = y_pred.shape[1]\n",
    "        r2s = []\n",
    "        for i in range(N_classes):\n",
    "            y_pred_one_class = y_pred[:,i]\n",
    "            y_true_one_class = y_true[:, i]\n",
    "            mask = ~(y_true_one_class == self.MASK)\n",
    "            r2 = r2_score(y_true_one_class[mask], y_pred_one_class[mask])\n",
    "            r2s.append(r2)\n",
    "        return r2s   \n",
    "    \n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        # The number of epoch it has waited when loss is no longer minimum.\n",
    "        self.wait = 0\n",
    "        # The epoch the training stops at.\n",
    "        self.stopped_epoch = 0\n",
    "        # Initialize the best as infinity.\n",
    "        if self.criteria == 'val_loss':\n",
    "            self.best = np.Inf  \n",
    "        else:\n",
    "            self.best = -np.Inf\n",
    "\n",
    " \n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        y_pred = self.model.predict(self.x)\n",
    "        rmse_list = self.rmse(self.y, y_pred)\n",
    "        rmse_mean = np.nanmean(rmse_list)\n",
    "        \n",
    "        r2_list = self.r2(self.y, y_pred) \n",
    "        r2_mean = np.nanmean(r2_list)\n",
    "        \n",
    "        \n",
    "        y_pred_val = self.model.predict(self.x_val)\n",
    "        rmse_list_val = self.rmse(self.y_val, y_pred_val)        \n",
    "        rmse_mean_val = np.nanmean(rmse_list_val)\n",
    "        \n",
    "        r2_list_val = self.r2(self.y_val, y_pred_val)       \n",
    "        r2_mean_val = np.nanmean(r2_list_val)        \n",
    "        \n",
    "        self.history['loss'].append(logs.get('loss'))\n",
    "        self.history['val_loss'].append(logs.get('val_loss'))\n",
    "        \n",
    "        self.history['rmse'].append(rmse_mean)\n",
    "        self.history['val_rmse'].append(rmse_mean_val)\n",
    "        \n",
    "        self.history['r2'].append(r2_mean)\n",
    "        self.history['val_r2'].append(r2_mean_val)        \n",
    "        \n",
    "        self.history['epoch'].append(epoch)\n",
    "        \n",
    "        \n",
    "        # logs is a dictionary\n",
    "        eph = str(epoch+1).zfill(4)   \n",
    "        loss = '{0:.4f}'.format((logs.get('loss')))\n",
    "        val_loss = '{0:.4f}'.format((logs.get('val_loss')))\n",
    "        rmse = '{0:.4f}'.format(rmse_mean)\n",
    "        rmse_val = '{0:.4f}'.format(rmse_mean_val)\n",
    "        r2_mean = '{0:.4f}'.format(r2_mean)\n",
    "        r2_mean_val = '{0:.4f}'.format(r2_mean_val)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('\\repoch: %s, loss: %s - val_loss: %s; rmse: %s - rmse_val: %s;  r2: %s - r2_val: %s' % (eph,\n",
    "                                                                                                           loss, val_loss, \n",
    "                                                                                                           rmse,rmse_val,\n",
    "                                                                                                           r2_mean,r2_mean_val),\n",
    "                  end=100*' '+'\\n')\n",
    "\n",
    "\n",
    "        if self.criteria == 'val_loss':\n",
    "            current = logs.get(self.criteria)\n",
    "            if current <= self.best:\n",
    "                self.best = current\n",
    "                self.wait = 0\n",
    "                # Record the best weights if current results is better (less).\n",
    "                self.best_weights = self.model.get_weights()\n",
    "                self.best_epoch = epoch\n",
    "\n",
    "            else:\n",
    "                self.wait += 1\n",
    "                if self.wait >= self.patience:\n",
    "                    self.stopped_epoch = epoch\n",
    "                    self.model.stop_training = True\n",
    "                    print('\\nRestoring model weights from the end of the best epoch.')\n",
    "                    self.model.set_weights(self.best_weights)    \n",
    "                    \n",
    "        else:\n",
    "            current = np.nanmean(r2_list_val)\n",
    "            \n",
    "            if current >= self.best:\n",
    "                self.best = current\n",
    "                self.wait = 0\n",
    "                # Record the best weights if current results is better (less).\n",
    "                self.best_weights = self.model.get_weights()\n",
    "                self.best_epoch = epoch\n",
    "\n",
    "            else:\n",
    "                self.wait += 1\n",
    "                if self.wait >= self.patience:\n",
    "                    self.stopped_epoch = epoch\n",
    "                    self.model.stop_training = True\n",
    "                    print('\\nRestoring model weights from the end of the best epoch.')\n",
    "                    self.model.set_weights(self.best_weights)              \n",
    "    \n",
    "    def on_train_end(self, logs=None):\n",
    "        self.model.set_weights(self.best_weights)\n",
    "        if self.stopped_epoch > 0:\n",
    "            print('\\nEpoch %05d: early stopping' % (self.stopped_epoch + 1))\n",
    "\n",
    "                \n",
    "    def evaluate(self, testX, testY):\n",
    "        \"\"\"evalulate, return rmse and r2\"\"\"\n",
    "        y_pred = self.model.predict(testX)\n",
    "        rmse_list = self.rmse(testY, y_pred, inner_y_true = False)\n",
    "        r2_list = self.r2(testY, y_pred, inner_y_true = False)\n",
    "        return rmse_list, r2_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CLA_EarlyStoppingAndPerformance(tf.keras.callbacks.Callback):\n",
    "    \"The callback class used in classification problems.\"\n",
    "    def __init__(self, train_data, valid_data, MASK = -1, patience=5, criteria = 'val_loss', metric = 'ROC', last_avf = None, verbose = 0):\n",
    "        super(CLA_EarlyStoppingAndPerformance, self).__init__()\n",
    "        \n",
    "        sp = ['val_loss', 'val_auc']\n",
    "        assert criteria in sp, 'not support %s ! only %s' % (criteria, sp)\n",
    "        self.x, self.y  = train_data\n",
    "        self.x_val, self.y_val = valid_data\n",
    "        self.last_avf = last_avf\n",
    "        \n",
    "        self.history = {'loss':[],\n",
    "                        'val_loss':[],\n",
    "                        'auc':[],\n",
    "                        'val_auc':[],\n",
    "                        \n",
    "                        'epoch':[]}\n",
    "        self.MASK = MASK\n",
    "        self.patience = patience\n",
    "        # best_weights to store the weights at which the minimum loss occurs.\n",
    "        self.best_weights = None\n",
    "        self.criteria = criteria\n",
    "        self.metric = metric\n",
    "        self.best_epoch = 0\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        s = 1/(1+np.exp(-x))\n",
    "        return s\n",
    "\n",
    "    \n",
    "    def roc_auc(self, y_true, y_pred):\n",
    "        if self.last_avf == None:\n",
    "            y_pred_logits = self.sigmoid(y_pred)\n",
    "        else:\n",
    "            y_pred_logits = y_pred\n",
    "            \n",
    "        N_classes = y_pred_logits.shape[1]\n",
    "\n",
    "        aucs = []\n",
    "        for i in range(N_classes):\n",
    "            y_pred_one_class = y_pred_logits[:,i]\n",
    "            y_true_one_class = y_true[:, i]\n",
    "            mask = ~(y_true_one_class == self.MASK)\n",
    "            try:\n",
    "                if self.metric == 'ROC':\n",
    "                    auc = roc_auc_score(y_true_one_class[mask], y_pred_one_class[mask]) #ROC_AUC\n",
    "                elif self.metric == 'PRC': \n",
    "                    auc = prc_auc_score(y_true_one_class[mask], y_pred_one_class[mask]) #PRC_AUC\n",
    "                elif self.metric == 'ACC':\n",
    "                    auc = accuracy_score(y_true_one_class[mask], np.round(y_pred_one_class[mask])) #ACC\n",
    "            except:\n",
    "                auc = np.nan\n",
    "            aucs.append(auc)\n",
    "        return aucs  \n",
    "    \n",
    "        \n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        # The number of epoch it has waited when loss is no longer minimum.\n",
    "        self.wait = 0\n",
    "        # The epoch the training stops at.\n",
    "        self.stopped_epoch = 0\n",
    "        # Initialize the best as infinity.\n",
    "        if self.criteria == 'val_loss':\n",
    "            self.best = np.Inf  \n",
    "        else:\n",
    "            self.best = -np.Inf\n",
    "            \n",
    "\n",
    "        \n",
    " \n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        y_pred = self.model.predict(self.x)\n",
    "        roc_list = self.roc_auc(self.y, y_pred)\n",
    "        roc_mean = np.nanmean(roc_list)\n",
    "        \n",
    "        y_pred_val = self.model.predict(self.x_val)\n",
    "        roc_val_list = self.roc_auc(self.y_val, y_pred_val)        \n",
    "        roc_val_mean = np.nanmean(roc_val_list)\n",
    "        \n",
    "        self.history['loss'].append(logs.get('loss'))\n",
    "        self.history['val_loss'].append(logs.get('val_loss'))\n",
    "        self.history['auc'].append(roc_mean)\n",
    "        self.history['val_auc'].append(roc_val_mean)\n",
    "        self.history['epoch'].append(epoch)\n",
    "        \n",
    "        \n",
    "        eph = str(epoch+1).zfill(4)        \n",
    "        loss = '{0:.4f}'.format((logs.get('loss')))\n",
    "        val_loss = '{0:.4f}'.format((logs.get('val_loss')))\n",
    "        auc = '{0:.4f}'.format(roc_mean)\n",
    "        auc_val = '{0:.4f}'.format(roc_val_mean)    \n",
    "        \n",
    "        if self.verbose:\n",
    "            if self.metric == 'ACC':\n",
    "                print('\\repoch: %s, loss: %s - val_loss: %s; acc: %s - val_acc: %s' % (eph,\n",
    "                                                                                   loss, \n",
    "                                                                                   val_loss, \n",
    "                                                                                   auc,\n",
    "                                                                                   auc_val), end=100*' '+'\\n')\n",
    "\n",
    "            else:\n",
    "                print('\\repoch: %s, loss: %s - val_loss: %s; auc: %s - val_auc: %s' % (eph,\n",
    "                                                                                   loss, \n",
    "                                                                                   val_loss, \n",
    "                                                                                   auc,\n",
    "                                                                                   auc_val), end=100*' '+'\\n')\n",
    "\n",
    "\n",
    "        if self.criteria == 'val_loss':\n",
    "            current = logs.get(self.criteria)\n",
    "            if current <= self.best:\n",
    "                self.best = current\n",
    "                self.wait = 0\n",
    "                # Record the best weights if current results is better (less).\n",
    "                self.best_weights = self.model.get_weights()\n",
    "                self.best_epoch = epoch\n",
    "\n",
    "            else:\n",
    "                self.wait += 1\n",
    "                if self.wait >= self.patience:\n",
    "                    self.stopped_epoch = epoch\n",
    "                    self.model.stop_training = True\n",
    "                    print('\\nRestoring model weights from the end of the best epoch.')\n",
    "                    self.model.set_weights(self.best_weights)    \n",
    "                    \n",
    "        else:\n",
    "            current = roc_val_mean\n",
    "            if current >= self.best:\n",
    "                self.best = current\n",
    "                self.wait = 0\n",
    "                # Record the best weights if current results is better (less).\n",
    "                self.best_weights = self.model.get_weights()\n",
    "                self.best_epoch = epoch\n",
    "\n",
    "            else:\n",
    "                self.wait += 1\n",
    "                if self.wait >= self.patience:\n",
    "                    self.stopped_epoch = epoch\n",
    "                    self.model.stop_training = True\n",
    "                    print('\\nRestoring model weights from the end of the best epoch.')\n",
    "                    self.model.set_weights(self.best_weights)              \n",
    "    \n",
    "    def on_train_end(self, logs=None):\n",
    "        self.model.set_weights(self.best_weights)\n",
    "        if self.stopped_epoch > 0:\n",
    "            print('\\nEpoch %05d: early stopping' % (self.stopped_epoch + 1))\n",
    "\n",
    "        \n",
    "    def evaluate(self, testX, testY):\n",
    "        \n",
    "        y_pred = self.model.predict(testX)\n",
    "        roc_list = self.roc_auc(testY, y_pred)\n",
    "        return roc_list            \n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

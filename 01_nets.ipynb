{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nets\n",
    "> The neural network architects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our implementation of the networks will follow this architecture:\n",
    "\n",
    "![](https://github.com/shenwanxiang/bidd-molmap/blob/master/paper/images/net.png?raw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "\n",
    "When building complex networks it's better to build and test the smaller components first, then combine them together. This way we can also reuse the individual parts easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional block\n",
    "\n",
    "This block takes the descriptor or  fingerprint maps as input, and returns outputs of a max pooling layer.\n",
    "\n",
    "- Descriptor: `13*37*37` -> `48*37*37` -> `48*19*19`\n",
    "- Fingerprint: `3*37*36` -> `48*37*36` -> `48*19*18`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Convnet(nn.Module):\n",
    "    \"Convolutional feature extraction Block\"\n",
    "    def __init__(self, C_in=13, C_out=48, conv_size=13):\n",
    "        super(Convnet, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(C_in, C_out, kernel_size=conv_size, stride=1, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        \n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it on the descriptor and fingerprint maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olivier/opt/anaconda3/envs/molmap/lib/python3.6/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 48, 19, 19])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convnet = Convnet()\n",
    "\n",
    "i = torch.rand((10, 13, 37, 37))\n",
    "o = convnet(i)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 48, 19, 18])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convnet = Convnet(3, 48)\n",
    "\n",
    "i = torch.rand((10, 3, 37, 36))\n",
    "o = convnet(i)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception block\n",
    "\n",
    "After the convolutional block, the resulting feature maps will further pass through some inception blocks. \n",
    "\n",
    "The inceptions implemented here are the naÃ¯ve Google inceptions. It passes the input through multiple convolutional layers and then concatenate the output. This inception block is actually two smaller inception blocks bridged with a max pooling layer. First the small inception block:\n",
    "\n",
    "- Descriptor: `48*19*19` -> 3 outputs of `32*19*19` -> `96*19*19`, |-> `96*10*10` -> 3 outputs of `64*10*10` -> `192*10*10`\n",
    "- Fingerprint: `48*19*18` -> 3 outputs of `32*19*18` -> `96*19*18`, |-> `96*10*9` -> 3 outputs of `64*10*9` -> `192*10*9`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Inception(nn.Module):\n",
    "    \"Naive Google Inception Block\"\n",
    "    def __init__(self, C_in=48, C_out=32, stride=1):\n",
    "        super(Inception, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(C_in, C_out, kernel_size=5, stride=stride, padding='same'),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(C_in, C_out, kernel_size=3, stride=stride, padding='same'),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(C_in, C_out, kernel_size=1, stride=stride, padding='same'),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x)\n",
    "        x3 = self.conv3(x)\n",
    "        \n",
    "        return torch.cat((x1, x2, x3), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 96, 19, 19])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception = Inception()\n",
    "\n",
    "i = torch.rand((10, 48, 19, 19))\n",
    "o = inception(i)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 192, 10, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception = Inception(96, 64)\n",
    "\n",
    "i = torch.rand((10, 96, 10, 10))\n",
    "o = inception(i)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 96, 19, 18])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception = Inception()\n",
    "\n",
    "i = torch.rand((10, 48, 19, 18))\n",
    "o = inception(i)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 192, 10, 9])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception = Inception(96, 64)\n",
    "\n",
    "i = torch.rand((10, 96, 10, 9))\n",
    "o = inception(i)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "And the double inception block:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DoubleInception(nn.Module):\n",
    "    \"Double Inception Block\"\n",
    "    def __init__(self, C_in1=48, C_out1=32, stride1=1, C_in2=96, C_out2=64, stride2=1):\n",
    "        super(DoubleInception, self).__init__()\n",
    "        \n",
    "        self.inception1 = Inception(C_in1, C_out1, stride1)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.inception2 = Inception(C_in2, C_out2, stride2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.inception1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.inception2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 192, 10, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_inception = DoubleInception()\n",
    "\n",
    "i = torch.rand((10, 48, 19, 19))\n",
    "o = double_inception(i)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 192, 10, 9])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_inception = DoubleInception()\n",
    "\n",
    "i = torch.rand((10, 48, 19, 18))\n",
    "o = double_inception(i)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global max pooling\n",
    "\n",
    "There is no global max pooling layer in PyTorch but this is very easy to realise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 192])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = torch.rand((10, 192, 10, 10))\n",
    "o = i.amax(dim=(-1, -2))\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully connected block\n",
    "\n",
    "At the end of the network the data passes through several fully connected layers. \n",
    "\n",
    "If the MolMap network is single path:\n",
    "\n",
    "- `192` -> `128` -> `32`\n",
    "\n",
    "And if double path:\n",
    "\n",
    "- `384` -> `256` -> `128` -> `32`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SinglePathFullyConnected(nn.Module):\n",
    "    \"Fully connected layers for single path MolMap nets\"\n",
    "    def __init__(self, C1=192, C2=128, C3=32):\n",
    "        super(SinglePathFullyConnected, self).__init__()\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(C1, C2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(C2, C3)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_path_fully_connected = SinglePathFullyConnected()\n",
    "\n",
    "i = torch.rand((10, 192))\n",
    "o = single_path_fully_connected(i)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DoublePathFullyConnected(nn.Module):\n",
    "    \"Fully connected layers for double paths MolMap nets\"\n",
    "    def __init__(self, C1=384, C2=256, C3=128, C4=32):\n",
    "        super(DoublePathFullyConnected, self).__init__()\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(C1, C2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(C2, C3),\n",
    "            nn.ReLU(),        \n",
    "            nn.Linear(C3, C4),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_path_fully_connected = DoublePathFullyConnected()\n",
    "\n",
    "i = torch.rand((10, 384))\n",
    "o = double_path_fully_connected(i)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Path Molecular Mapping network\n",
    "\n",
    "Descriptor map or Fingerprint map only. The two feature maps use identical network structures and only differ in data shape. Note that we need to specify the number of channels for the feature maps when initialising the model, but the model should be able to handle feature maps with different dimensions.\n",
    "\n",
    "- descriptor: `13*37*37` -> `32`\n",
    "- fingerprint: `3*37*36` -> `32`\n",
    "\n",
    "The output layer is not included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SinglePathMolMapNet(nn.Module):\n",
    "    \"Single Path Molecular Mapping Network\"\n",
    "    def __init__(self, conv_in=13, conv_size=13, FC=[128, 32]):\n",
    "        super(SinglePathMolMapNet, self).__init__()\n",
    "        \n",
    "        # output channels in the double inception\n",
    "        C_out1, C_out2 = 32, 64\n",
    "        \n",
    "        self.conv = Convnet(C_in=conv_in, C_out=48, conv_size=conv_size)\n",
    "        self.double_inception = DoubleInception(C_in1=48, C_out1=C_out1, C_in2=C_out1*3, C_out2=C_out2)\n",
    "        self.fully_connected = SinglePathFullyConnected(C1=C_out2*3, C2=FC[0], C3=FC[1])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.double_inception(x)\n",
    "        x = x.amax(dim=(-1, -2))\n",
    "        x = self.fully_connected(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_path = SinglePathMolMapNet()\n",
    "\n",
    "i = torch.rand((10, 13, 37, 37))\n",
    "o = single_path(i)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_path = SinglePathMolMapNet(conv_in=3)\n",
    "\n",
    "i = torch.rand((10, 3, 37, 36))\n",
    "o = single_path(i)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double Path Molecular Mapping network\n",
    "\n",
    "Both the descriptor map and Fingerprint map will pass through the convolutional block, then the double inception block, and their results are then combined, before finally pass through the fully connected layers. \n",
    "\n",
    "After convolutional and double inception block:\n",
    "\n",
    "- descriptor: `13*37*37` -> `192*10*10`\n",
    "- fingerprint: `3*37*36` -> `192*10*9`\n",
    "\n",
    "After global max pooling:\n",
    "\n",
    "- descriptor: `192*10*10` -> `192`\n",
    "- fingerprint: `192*10*9` -> `192`\n",
    "\n",
    "After Concatenation and fully connected blocks:\n",
    "\n",
    "- `192 + 192` -> `384` -> `32`\n",
    "\n",
    "The output layer is not included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DoublePathMolMapNet(nn.Module):\n",
    "    \"Double Path Molecular Mapping Network\"\n",
    "    def __init__(self, conv_in1=13, conv_in2=3, conv_size=13, FC=[256, 128, 32]):\n",
    "        super(DoublePathMolMapNet, self).__init__()\n",
    "        \n",
    "        # output channels in the double inception\n",
    "        C_out1, C_out2 = 32, 64\n",
    "        \n",
    "        self.conv1 = Convnet(C_in=conv_in1, C_out=48, conv_size=conv_size)        \n",
    "        self.conv2 = Convnet(C_in=conv_in2, C_out=48, conv_size=conv_size)\n",
    "        self.double_inception = DoubleInception(C_in1=48, C_out1=C_out1, C_in2=C_out1*3, C_out2=C_out2)        \n",
    "        self.fully_connected = DoublePathFullyConnected(C1=C_out2*6, C2=FC[0], C3=FC[1], C4=FC[2])\n",
    "                \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.conv1(x1)\n",
    "        x1 = self.double_inception(x1)\n",
    "        x1 = x1.amax(dim=(-1, -2))\n",
    "        \n",
    "        x2 = self.conv2(x2)\n",
    "        x2 = self.double_inception(x2)\n",
    "        x2 = x2.amax(dim=(-1, -2))\n",
    "        \n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.fully_connected(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_path = DoublePathMolMapNet()\n",
    "\n",
    "i1 = torch.rand((10, 13, 37, 37))\n",
    "i2 = torch.rand((10, 3, 37, 36))\n",
    "o = double_path(i1, i2)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet block\n",
    "\n",
    "Currently not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Resnet(nn.Module):\n",
    "    \"Naive Google Inception Block\"\n",
    "    def __init__(self, C, conv_size):\n",
    "        super(Resnet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(C, C, kernel_size=conv_size, stride=1, padding='same'),\n",
    "            nn.BatchNorm2d(C),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(C, C, kernel_size=conv_size, stride=1, padding='same'),\n",
    "            nn.BatchNorm2d(C)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        o = self.conv1(x)\n",
    "        o = self.conv2(o)\n",
    "        o += x\n",
    "        \n",
    "        return F.relu(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 48, 19, 18])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = Resnet(48, 5)\n",
    "\n",
    "i = torch.rand((10, 48, 19, 18))\n",
    "o = resnet(i)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

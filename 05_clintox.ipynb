{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d654c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0af3602",
   "metadata": {},
   "source": [
    "# clintox\n",
    "> Using molmapnets for multi-label classification, with descriptors, or fingerprints, or both. Tested on the [ClinTox](http://moleculenet.ai/datasets-1) dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0131a410-c2c6-424c-a1f4-6a2935436eb6",
   "metadata": {},
   "source": [
    "Per it's own documentation:\n",
    "\n",
    "> Qualitative data of drugs approved by the FDA and those that have failed clinical trials for toxicity reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08473ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967d2377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b581d8-3fb3-4863-87f4-c7a582278706",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [14:57:53] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "from chembench import dataset\n",
    "from molmap import MolMap, feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee0ec11-c6a8-41c5-9383-e2404e48aa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from molmapnets.data import SingleFeatureData, DoubleFeatureData\n",
    "from molmapnets.models import MolMapMultiLabelClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a291a8b2",
   "metadata": {},
   "source": [
    "## Feature extraction \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c669416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples: 1478\n"
     ]
    }
   ],
   "source": [
    "data = dataset.load_ClinTox()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c1e4b4-fba9-4b8a-bfd1-dc6c98abc4e5",
   "metadata": {},
   "source": [
    "Take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08c5023-70c8-4cc0-bd5f-930fa681af09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>smiles</th>\n",
       "      <th>FDA_APPROVED</th>\n",
       "      <th>CT_TOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>*C(=O)[C@H](CCCCNC(=O)OCCOC)NC(=O)OCCOC</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[C@@H]1([C@@H]([C@@H]([C@H]([C@@H]([C@@H]1Cl)C...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[C@H]([C@@H]([C@@H](C(=O)[O-])O)O)([C@H](C(=O)...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[H]/[NH+]=C(/C1=CC(=O)/C(=C\\C=c2ccc(=C([NH3+])...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[H]/[NH+]=C(\\N)/c1ccc(cc1)OCCCCCOc2ccc(cc2)/C(...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                             smiles  FDA_APPROVED  \\\n",
       "0      0            *C(=O)[C@H](CCCCNC(=O)OCCOC)NC(=O)OCCOC             1   \n",
       "1      1  [C@@H]1([C@@H]([C@@H]([C@H]([C@@H]([C@@H]1Cl)C...             1   \n",
       "2      2  [C@H]([C@@H]([C@@H](C(=O)[O-])O)O)([C@H](C(=O)...             1   \n",
       "3      3  [H]/[NH+]=C(/C1=CC(=O)/C(=C\\C=c2ccc(=C([NH3+])...             1   \n",
       "4      4  [H]/[NH+]=C(\\N)/c1ccc(cc1)OCCCCCOc2ccc(cc2)/C(...             1   \n",
       "\n",
       "   CT_TOX  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bad9cfe-d67f-45be-bba0-b09d92cd0321",
   "metadata": {},
   "source": [
    "This is a two class classification data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae4cedb-6f3e-4ee8-81a0-96b1d5070d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.df.FDA_APPROVED.nunique(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5966213d-1c28-482d-b8f4-5127adc3c7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.df.FDA_APPROVED.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767235ff-5280-439d-9954-9c9ab72c686a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.df.CT_TOX.nunique(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0054e31-e61e-4dc8-baab-2fa37ec6446a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.df.CT_TOX.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0cbc40",
   "metadata": {},
   "source": [
    "Create feature map objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad885be-d0eb-42fa-9e58-3650f07dfd19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PubChemFP0', 'PubChemFP1', 'PubChemFP2', 'PubChemFP3', 'PubChemFP4']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitsinfo = feature.fingerprint.Extraction().bitsinfo\n",
    "flist = bitsinfo[bitsinfo.Subtypes.isin(['PubChemFP'])].IDs.tolist()\n",
    "\n",
    "flist[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651a8fab-4e4a-46f7-88be-1e8a79e360b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor = MolMap(ftype='descriptor', metric='cosine',)\n",
    "fingerprint = MolMap(ftype='fingerprint', fmap_type='scatter', flist=flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776cdbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-23 14:58:08,834 - INFO - [bidd-molmap] - Applying grid feature map(assignment), this may take several minutes(1~30 min)\n",
      "2021-07-23 14:58:11,974 - INFO - [bidd-molmap] - Finished\n"
     ]
    }
   ],
   "source": [
    "descriptor.fit(verbose=0, method='umap', min_dist=0.1, n_neighbors=15,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20423af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-23 14:58:13,073 - INFO - [bidd-molmap] - Applying naive scatter feature map...\n",
      "2021-07-23 14:58:13,095 - INFO - [bidd-molmap] - Finished\n"
     ]
    }
   ],
   "source": [
    "fingerprint.fit(verbose=0, method='umap', min_dist=0.1, n_neighbors=15,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e0bffa-cff3-4c5e-8ffd-d9c61c6fa16a",
   "metadata": {},
   "source": [
    "Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbb99e4-a3d9-4b02-a38d-e55a7e9ff18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1478/1478 [08:20<00:00,  3.61it/s]\n",
      "100%|##########| 1478/1478 [02:07<00:00, 14.06it/s]\n"
     ]
    }
   ],
   "source": [
    "X1 = descriptor.batch_transform(data.x)\n",
    "X2 = fingerprint.batch_transform(data.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831ae943-6276-4626-bce6-0d6f57fd4e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1478, 37, 37, 13)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e61a8e7-0e76-4ad5-a2f9-ddd54461d34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1478, 52, 52, 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1cc63b-344f-4611-b2bb-bba90b0fc326",
   "metadata": {},
   "source": [
    "We also need to transform the outcome variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87164e0-66e1-4758-b393-43acbb730f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1478, 2)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = data.y\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d789b197-976e-44c9-93cd-277baa978a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4347fca4",
   "metadata": {},
   "source": [
    "## Classification using only the descriptor map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f60340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_feature = SingleFeatureData(Y, X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ba89e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = random_split(single_feature, [1184, 147, 147], generator=torch.Generator().manual_seed(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79962896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1184, 147, 147)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(val), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae870cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9c26f3",
   "metadata": {},
   "source": [
    "And we can get one batch of data by making the data loader iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ed67cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebae73cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a76d4f-b821-4c8b-a963-05b842ebf870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af725f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 13, 37, 37])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173afeb6",
   "metadata": {},
   "source": [
    "Finally with the data prepared we can train the models. These are tests to show that the models work as expected, but we can certainly fine tune the training loop to achieve better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbce54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MolMapMultiLabelClassification(n_label=2)\n",
    "\n",
    "epochs = 5\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e415c060-8c56-4405-8032-b8676baaf000",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olivier/opt/anaconda3/envs/molmap/lib/python3.6/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4808, 0.5071],\n",
       "        [0.4809, 0.5071],\n",
       "        [0.4808, 0.5071],\n",
       "        [0.4809, 0.5071],\n",
       "        [0.4809, 0.5071],\n",
       "        [0.4808, 0.5071],\n",
       "        [0.4808, 0.5071],\n",
       "        [0.4808, 0.5071]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f7c438-61c0-47ae-a8d1-d0ba604ad7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7133, grad_fn=<BinaryCrossEntropyBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(model(x), t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa88bf3a",
   "metadata": {},
   "source": [
    "And the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a9e3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1, Iter:    50] Training loss: 0.351\n",
      "[Epoch: 1, Iter:   100] Training loss: 0.305\n",
      "[Epoch: 2, Iter:    50] Training loss: 0.221\n",
      "[Epoch: 2, Iter:   100] Training loss: 0.277\n",
      "[Epoch: 3, Iter:    50] Training loss: 0.281\n",
      "[Epoch: 3, Iter:   100] Training loss: 0.277\n",
      "[Epoch: 4, Iter:    50] Training loss: 0.313\n",
      "[Epoch: 4, Iter:   100] Training loss: 0.273\n",
      "[Epoch: 5, Iter:    50] Training loss: 0.258\n",
      "[Epoch: 5, Iter:   100] Training loss: 0.253\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, (xb, yb) in enumerate(train_loader):\n",
    "        \n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward propagation\n",
    "        pred = model(xb)\n",
    "\n",
    "        # loss calculation\n",
    "        loss = criterion(pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if (i+1) % 50 == 0:    \n",
    "            print('[Epoch: %d, Iter: %5d] Training loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / (i+1)))\n",
    "\n",
    "print('Training finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683c1ba4-66cd-4231-b437-fd986a94dc5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((model(x) > 0.5).float() == t).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772731a8-0e97-4173-a286-0dbeb4466663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).nelement()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab507bf8",
   "metadata": {},
   "source": [
    "And let's look at the prediction accuracy on validation data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2a418e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test data: 93 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (xb, yb) in enumerate(val_loader):\n",
    "\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        pred = model(xb)\n",
    "\n",
    "        # accuracy calculation\n",
    "        total += yb.nelement()\n",
    "        correct += ((pred > 0.5).float()==yb).sum().item()\n",
    "\n",
    "        \n",
    "print('Accuracy of the network on the test data: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c478288-e476-4280-83e4-2a8797a6647b",
   "metadata": {},
   "source": [
    "## Classification using both feature maps\n",
    "\n",
    "\n",
    "Now we can feed both the feature maps to the model as a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a1ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_feature = DoubleFeatureData(Y, (X1, X2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9217de48-9c9e-4637-b94a-7c8b2de804d6",
   "metadata": {},
   "source": [
    "split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601b50fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_double, val_double, test_double = random_split(double_feature, [1184, 147, 147], generator=torch.Generator().manual_seed(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89a52a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1184, 147, 147)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_double), len(val_double), len(test_double)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd457be-a797-4663-84cf-2fce4ac257e4",
   "metadata": {},
   "source": [
    "Prepare batch data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a83e71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_double = DataLoader(train_double, batch_size=8, shuffle=True)\n",
    "val_loader_double = DataLoader(val_double, batch_size=8, shuffle=True)\n",
    "test_loader_double = DataLoader(test_double, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1b3ba1",
   "metadata": {},
   "source": [
    "And we can get one batch of data by making the data loader iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246b96df",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t = next(iter(train_loader_double))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd427cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88730ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 13, 37, 37]), torch.Size([8, 1, 52, 52]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1, x2 = x\n",
    "x1.shape, x2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d407b9",
   "metadata": {},
   "source": [
    "And multi-label classification. Different feature maps have different number of channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4b0a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_double = MolMapMultiLabelClassification(conv_in1=13, conv_in2=1, n_label=2)\n",
    "\n",
    "epochs = 5\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_double.to(device)\n",
    "optimizer = optim.Adam(model_double.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af565cc7",
   "metadata": {},
   "source": [
    "And the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d00f01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1, Iter:    50] Training loss: 0.304\n",
      "[Epoch: 1, Iter:   100] Training loss: 0.301\n",
      "[Epoch: 2, Iter:    50] Training loss: 0.307\n",
      "[Epoch: 2, Iter:   100] Training loss: 0.284\n",
      "[Epoch: 3, Iter:    50] Training loss: 0.273\n",
      "[Epoch: 3, Iter:   100] Training loss: 0.288\n",
      "[Epoch: 4, Iter:    50] Training loss: 0.269\n",
      "[Epoch: 4, Iter:   100] Training loss: 0.229\n",
      "[Epoch: 5, Iter:    50] Training loss: 0.283\n",
      "[Epoch: 5, Iter:   100] Training loss: 0.254\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, ((x1, x2), yb) in enumerate(train_loader_double):\n",
    "\n",
    "        x1, x2, yb = x1.to(device), x2.to(device), yb.to(device)\n",
    "\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward propagation\n",
    "        pred = model_double((x1, x2))\n",
    "\n",
    "        # loss calculation\n",
    "        loss = criterion(pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if (i+1) % 50 == 0:    \n",
    "            print('[Epoch: %d, Iter: %5d] Training loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / (i+1)))\n",
    "\n",
    "print('Training finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940f58be",
   "metadata": {},
   "source": [
    "Accuracy on the validation data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de7cd40-ea1d-499a-812f-e82d5958edf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test data: 93 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, ((x1, x2), yb) in enumerate(val_loader_double):\n",
    "\n",
    "        x1, x2, yb = x1.to(device), x2.to(device), yb.to(device)\n",
    "\n",
    "        pred = model_double((x1, x2))\n",
    "\n",
    "        # accuracy calculation\n",
    "        total += yb.nelement()\n",
    "        correct += ((pred > 0.5).float()==yb).sum().item()\n",
    "\n",
    "        \n",
    "print('Accuracy of the network on the test data: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6370c4-587e-4893-9492-b6f6dd6cc5a9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

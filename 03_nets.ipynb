{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nets\n",
    "> The neural network architects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our implementation of the networks will follow this architecture:\n",
    "\n",
    "![](https://github.com/shenwanxiang/bidd-molmap/blob/master/paper/images/net.png?raw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "\n",
    "When building complex networks it's better to build and test the smaller components first, then combine them together. This way we can also reuse the individual parts easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional block\n",
    "\n",
    "This block takes the descriptor or  fingerprint maps as input, and returns outputs of a max pooling layer.\n",
    "\n",
    "- Descriptor: `13*37*37` -> `48*37*37` -> `48*19*19`\n",
    "- Fingerprint: `3*37*36` -> `48*37*36` -> `48*19*18`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Convnet(nn.Module):\n",
    "    \"Convolutional feature extraction Block\"\n",
    "    def __init__(self, C_in=13, C_out=48, conv_size=13):\n",
    "        super(Convnet, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(C_in, C_out, kernel_size=conv_size, stride=1, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it on the descriptor and fingerprint maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 48, 19, 19])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convnet = Convnet()\n",
    "\n",
    "i = torch.rand((10, 13, 37, 37))\n",
    "o = convnet(i)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 48, 19, 18])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convnet = Convnet(3, 48)\n",
    "\n",
    "i = torch.rand((10, 3, 37, 36))\n",
    "o = convnet(i)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception block\n",
    "\n",
    "After the convolutional block, the resulting feature maps will further pass through some inception blocks. \n",
    "\n",
    "The inceptions implemented here are the naÃ¯ve Google inceptions. It passes the input through multiple convolutional layers and then concatenate the output. This inception block is actually two smaller inception blocks bridged with a max pooling layer. First the small inception block:\n",
    "\n",
    "- Descriptor: `48*19*19` -> 3 outputs of `32*19*19` -> `96*19*19`, |-> `96*10*10` -> 3 outputs of `64*10*10` -> `192*10*10`\n",
    "- Fingerprint: `48*19*18` -> 3 outputs of `32*19*18` -> `96*19*18`, |-> `96*10*9` -> 3 outputs of `64*10*9` -> `192*10*9`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Inception(nn.Module):\n",
    "    \"Naive Google Inception Block\"\n",
    "    def __init__(self, C_in=48, C_out=32, stride=1):\n",
    "        super(Inception, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(C_in, C_out, kernel_size=5, stride=stride, padding='same'),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(C_in, C_out, kernel_size=3, stride=stride, padding='same'),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(C_in, C_out, kernel_size=1, stride=stride, padding='same'),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x)\n",
    "        x3 = self.conv3(x)\n",
    "        \n",
    "        return torch.cat((x1, x2, x3), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 96, 19, 19])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception = Inception()\n",
    "\n",
    "i = torch.rand((10, 48, 19, 19))\n",
    "o = inception(i)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 192, 10, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception = Inception(96, 64)\n",
    "\n",
    "i = torch.rand((10, 96, 10, 10))\n",
    "o = inception(i)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 96, 19, 18])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception = Inception()\n",
    "\n",
    "i = torch.rand((10, 48, 19, 18))\n",
    "o = inception(i)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 192, 10, 9])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception = Inception(96, 64)\n",
    "\n",
    "i = torch.rand((10, 96, 10, 9))\n",
    "o = inception(i)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "And the double inception block:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DoubleInception(nn.Module):\n",
    "    \"Double Inception Block\"\n",
    "    def __init__(self, C_in1=48, C_out1=32, stride1=1, C_in2=96, C_out2=64, stride2=1):\n",
    "        super(DoubleInception, self).__init__()\n",
    "        \n",
    "        self.inception1 = Inception(C_in1, C_out1, stride1)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.inception2 = Inception(C_in2, C_out2, stride2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.inception1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.inception2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 192, 10, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_inception = DoubleInception()\n",
    "\n",
    "i = torch.rand((10, 48, 19, 19))\n",
    "o = double_inception(i)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 192, 10, 9])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_inception = DoubleInception()\n",
    "\n",
    "i = torch.rand((10, 48, 19, 18))\n",
    "o = double_inception(i)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global max pooling\n",
    "\n",
    "There is no global max pooling layer in PyTorch but this is very easy to realise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 192])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = torch.rand((10, 192, 10, 10))\n",
    "o = i.amax(dim=(-1, -2))\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully connected block\n",
    "\n",
    "At the end of the network the data passes through several fully connected layers. \n",
    "\n",
    "If the MolMap network is single path:\n",
    "\n",
    "- `192` -> `128` -> `32`\n",
    "\n",
    "And if double path:\n",
    "\n",
    "- `384` -> `256` -> `128` -> `32`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SinglePathFullyConnected(nn.Module):\n",
    "    \"Fully connected layers for single path MolMap nets\"\n",
    "    def __init__(self, C1=192, C2=128, C3=32):\n",
    "        super(SinglePathFullyConnected, self).__init__()\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(C1, C2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(C2, C3)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_path_fully_connected = SinglePathFullyConnected()\n",
    "\n",
    "i = torch.rand((10, 192))\n",
    "o = single_path_fully_connected(i)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DoublePathFullyConnected(nn.Module):\n",
    "    \"Fully connected layers for double paths MolMap nets\"\n",
    "    def __init__(self, C1=384, C2=256, C3=128, C4=32):\n",
    "        super(DoublePathFullyConnected, self).__init__()\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(C1, C2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(C2, C3),\n",
    "            nn.ReLU(),        \n",
    "            nn.Linear(C3, C4),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_path_fully_connected = DoublePathFullyConnected()\n",
    "\n",
    "i = torch.rand((10, 384))\n",
    "o = double_path_fully_connected(i)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Path Molecular Mapping network\n",
    "\n",
    "Descriptor map or Fingerprint map only. The two have identical network structures, and only differs in data shape.\n",
    "\n",
    "- descriptor: `13*37*37` -> `32`\n",
    "- fingerprint: `3*37*36` -> `32`\n",
    "\n",
    "The output layer is not included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SinglePathMolMapNet(nn.Module):\n",
    "    \"Single Path Molecular Mapping Network\"\n",
    "    def __init__(self, \n",
    "                 conv_in=13, conv_out=48, conv_size=13,\n",
    "                 incept_in1=48, incept_out1=32, incept_stride1=1, incept_in2=96, incept_out2=64, incept_stride2=1,\n",
    "                 C1=192, C2=128, C3=32):\n",
    "        super(SinglePathMolMapNet, self).__init__()\n",
    "        \n",
    "        self.conv = Convnet(C_in=conv_in, C_out=conv_out, conv_size=conv_size)\n",
    "        self.double_inception = DoubleInception(\n",
    "            C_in1=incept_in1, C_out1=incept_out1, stride1=incept_stride1,\n",
    "            C_in2=incept_in2, C_out2=incept_out2, stride2=incept_stride2)\n",
    "        self.fully_connected = SinglePathFullyConnected(C1=C1, C2=C2, C3=C3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.double_inception(x)\n",
    "        x = x.amax(dim=(-1, -2))\n",
    "        x = self.fully_connected(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_path = SinglePathMolMapNet()\n",
    "\n",
    "i = torch.rand((10, 13, 37, 37))\n",
    "o = single_path(i)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_path = SinglePathMolMapNet(conv_in=3)\n",
    "\n",
    "i = torch.rand((10, 3, 37, 36))\n",
    "o = single_path(i)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual path Molecular Mapping network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additive path Molecular Mapping network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Molecular Mapping network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet block\n",
    "\n",
    "Thought not used Note that in the first conv net the activation is *before* batch normalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Resnet(nn.Module):\n",
    "    \"Naive Google Inception Block\"\n",
    "    def __init__(self, C, conv_size):\n",
    "        super(Resnet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(C, C, kernel_size=conv_size, stride=1, padding='same'),\n",
    "            nn.BatchNorm2d(C),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(C, C, kernel_size=conv_size, stride=1, padding='same'),\n",
    "            nn.BatchNorm2d(C)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        o = self.conv1(x)\n",
    "        o = self.conv2(o)\n",
    "        o += x\n",
    "        \n",
    "        return F.relu(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 48, 19, 18])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = Resnet(48, 5)\n",
    "\n",
    "i = torch.rand((10, 48, 19, 18))\n",
    "o = resnet(i)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

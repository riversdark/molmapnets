{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d654c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp esol\n",
    "#all_slow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0af3602",
   "metadata": {},
   "source": [
    "# esol\n",
    "> Using molmapnets for regression, with descriptors, or fingerprints, or both. Tested on the [eSOL](http://www.tanpaku.org/tp-esol/index.php?lang=en) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08473ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acce1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg  width=\"440\" height=\"55\"><rect x=\"0\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#66c2a5;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"55\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#fc8d62;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"110\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#8da0cb;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"165\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#e78ac3;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"220\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#a6d854;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"275\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#ffd92f;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"330\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#e5c494;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"385\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#b3b3b3;stroke-width:2;stroke:rgb(255,255,255)\"/></svg>"
      ],
      "text/plain": [
       "[(0.4, 0.7607843137254902, 0.6470588235294118),\n",
       " (0.9882352941176471, 0.5529411764705883, 0.3843137254901961),\n",
       " (0.5529411764705883, 0.6274509803921569, 0.796078431372549),\n",
       " (0.9058823529411765, 0.5411764705882353, 0.7647058823529411),\n",
       " (0.6509803921568628, 0.8470588235294118, 0.32941176470588235),\n",
       " (1.0, 0.8509803921568627, 0.1843137254901961),\n",
       " (0.8980392156862745, 0.7686274509803922, 0.5803921568627451),\n",
       " (0.7019607843137254, 0.7019607843137254, 0.7019607843137254)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_theme(palette='Set2')\n",
    "colors = sns.color_palette()\n",
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967d2377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b581d8-3fb3-4863-87f4-c7a582278706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chembench import dataset\n",
    "from molmap import MolMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee0ec11-c6a8-41c5-9383-e2404e48aa6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [21:38:06] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "from molmapnets.data import SingleFeatureData, DoubleFeatureData\n",
    "from molmapnets.models import MolMapRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a291a8b2",
   "metadata": {},
   "source": [
    "## Feature extraction \n",
    "\n",
    "The `chembench` package collected several different datasets for benchmarking the models. Here we'll use the [`eSOL`](http://www.tanpaku.org/tp-esol/index.php?lang=en) dataset, which collects the solubility of all E.coli proteins. The data can be loaded with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c669416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples: 1128\n"
     ]
    }
   ],
   "source": [
    "data = dataset.load_ESOL()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d347947f",
   "metadata": {},
   "source": [
    "We have the smiles (Simplified Molecular Input Line Entry Specification) for different proteins and their corresponding solubility meansure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08422aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>measured log solubility in mols per litre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)...</td>\n",
       "      <td>-0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Cc1occc1C(=O)Nc2ccccc2</td>\n",
       "      <td>-3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CC(C)=CCCC(C)=CC(=O)</td>\n",
       "      <td>-2.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43</td>\n",
       "      <td>-7.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>c1ccsc1</td>\n",
       "      <td>-1.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles  \\\n",
       "0  OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)...   \n",
       "1                             Cc1occc1C(=O)Nc2ccccc2   \n",
       "2                               CC(C)=CCCC(C)=CC(=O)   \n",
       "3                 c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43   \n",
       "4                                            c1ccsc1   \n",
       "\n",
       "   measured log solubility in mols per litre  \n",
       "0                                      -0.77  \n",
       "1                                      -3.30  \n",
       "2                                      -2.06  \n",
       "3                                      -7.87  \n",
       "4                                      -1.33  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0cbc40",
   "metadata": {},
   "source": [
    "Using MolMap we can extract features from using the smiles as input. We can specify the feature type `ftype`,  feature pairwise distance calculation method `metric`, and feature grid arrangement method `fmap_type`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5e87fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mMolMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mftype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'descriptor'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mflist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfmap_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'grid'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfmap_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msplit_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cosine'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvar_thr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      <no docstring>\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "paramters\n",
       "-----------------\n",
       "ftype: {'fingerprint', 'descriptor'}, feature type\n",
       "flist: feature list, if you want use some of the features instead of all features, each element in flist should be the id of a feature\n",
       "fmap_shape: None or tuple, size of molmap, only works when fmap_type is 'scatter', if None, the size of feature map will be calculated automatically\n",
       "fmap_type:{'scatter', 'grid'}, default: 'gird', if 'scatter', will return a scatter mol map without an assignment to a grid\n",
       "split_channels: bool, if True, outputs will split into various channels using the types of feature\n",
       "metric: {'cosine', 'correlation'}, default: 'cosine', measurement of feature distance\n",
       "var_thr: float, defalt is 1e-4, meaning that feature will be included only if the conresponding variance larger than this value. Since some of the feature has pretty low variances, we can remove them by increasing this threshold\n",
       "\u001b[0;31mFile:\u001b[0m           ~/git/bidd-molmap/molmap/map.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MolMap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a90652",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor = MolMap(ftype='descriptor', metric='cosine',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ad0944",
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerprint = MolMap(ftype='fingerprint', metric='cosine')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605bbe67",
   "metadata": {},
   "source": [
    "After setting up the feature extracting method, we can then use the `.fit` method of the feature object to extract the features. During this step we need to specify the algorithm (`method`) to embed higher dimensional features to 2D presentation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776cdbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-22 21:38:23,335 - INFO - [bidd-molmap] - Applying grid feature map(assignment), this may take several minutes(1~30 min)\n",
      "2021-07-22 21:38:26,510 - INFO - [bidd-molmap] - Finished\n"
     ]
    }
   ],
   "source": [
    "descriptor.fit(verbose=0, method='umap', min_dist=0.1, n_neighbors=15,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20423af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olivier/.local/lib/python3.6/site-packages/umap/umap_.py:1461: UserWarning: Using precomputed metric; transform will be unavailable for new data\n",
      "  \"Using precomputed metric; transform will be unavailable for new data\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-22 21:38:54,356 - INFO - [bidd-molmap] - Applying grid feature map(assignment), this may take several minutes(1~30 min)\n",
      "2021-07-22 22:11:46,397 - INFO - [bidd-molmap] - Finished\n"
     ]
    }
   ],
   "source": [
    "fingerprint.fit(verbose=0, method='umap', min_dist=0.1, n_neighbors=10,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f399d54",
   "metadata": {},
   "source": [
    "We can visualise the feature maps easily with MolMap, but the visualisations are removed to avoid crushing the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4347fca4",
   "metadata": {},
   "source": [
    "## Regression using the descriptor map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590c13a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1128/1128 [08:45<00:00,  2.35it/s]\n"
     ]
    }
   ],
   "source": [
    "X = descriptor.batch_transform(data.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdb9628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1128, 37, 37, 13)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01660061",
   "metadata": {},
   "source": [
    "In PyTorch the training data for computer vision problems takes the shape `(n_channels, hight, width)`, while the features extracted from `MolMap` take the shape `(hight, width, n_channels)`, so we'll first correct it by moving the channels dimension before the feature map dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4e2632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1128, 13, 37, 37])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.movedim(torch.from_numpy(X), -1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c886b0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3501a2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1128, 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1d44ed",
   "metadata": {},
   "source": [
    "Now from these feature maps we can create the dataset suitable for training models in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f60340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "esol = SingleFeatureData(data.y, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ba89e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = random_split(esol, [904,112,112], generator=torch.Generator().manual_seed(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79962896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(904, 112, 112)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(val), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae870cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9c26f3",
   "metadata": {},
   "source": [
    "And we can get one batch of data by making the data loader iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ed67cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebae73cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3560],\n",
       "        [-2.4840],\n",
       "        [-1.0600],\n",
       "        [ 0.3900],\n",
       "        [ 0.9600],\n",
       "        [-2.1700],\n",
       "        [-2.7300],\n",
       "        [-0.6200]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af725f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 13, 37, 37])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173afeb6",
   "metadata": {},
   "source": [
    "Finally with the data prepared we can train the models. These are tests to show that the models work as expected, but we can certainly fine tune the model to achieve better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbce54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MolMapRegression()\n",
    "\n",
    "epochs = 5\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa88bf3a",
   "metadata": {},
   "source": [
    "And the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a9e3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olivier/opt/anaconda3/envs/molmap/lib/python3.6/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1, Iter:    50] Training loss: 6.567\n",
      "[Epoch: 1, Iter:   100] Training loss: 5.444\n",
      "[Epoch: 2, Iter:    50] Training loss: 3.304\n",
      "[Epoch: 2, Iter:   100] Training loss: 2.579\n",
      "[Epoch: 3, Iter:    50] Training loss: 2.061\n",
      "[Epoch: 3, Iter:   100] Training loss: 1.807\n",
      "[Epoch: 4, Iter:    50] Training loss: 1.179\n",
      "[Epoch: 4, Iter:   100] Training loss: 1.294\n",
      "[Epoch: 5, Iter:    50] Training loss: 1.191\n",
      "[Epoch: 5, Iter:   100] Training loss: 1.397\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, (xb, yb) in enumerate(train_loader):\n",
    "\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward propagation\n",
    "        pred = model(xb)\n",
    "\n",
    "        # loss calculation\n",
    "        loss = criterion(pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if (i+1) % 50 == 0:    \n",
    "            print('[Epoch: %d, Iter: %5d] Training loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / (i+1)))\n",
    "\n",
    "print('Training finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab507bf8",
   "metadata": {},
   "source": [
    "Loss on validation data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2a418e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter:     3] Validation loss: 0.732\n",
      "[Iter:     6] Validation loss: 0.950\n",
      "[Iter:     9] Validation loss: 0.959\n",
      "[Iter:    12] Validation loss: 0.983\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for i, (xb, yb) in enumerate(val_loader):\n",
    "\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        # forward propagation\n",
    "        pred = model(xb)\n",
    "\n",
    "        # loss calculation\n",
    "        loss = criterion(pred, yb)\n",
    "        running_loss += loss.item()\n",
    "        if (i+1) % 3 == 0:    \n",
    "            print('[Iter: %5d] Validation loss: %.3f' %\n",
    "                    (i + 1, running_loss / (i+1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5440e3",
   "metadata": {},
   "source": [
    "## Regression using the fingerprint map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bf514c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1128/1128 [03:37<00:00,  5.55it/s]\n"
     ]
    }
   ],
   "source": [
    "X_fingerprint = fingerprint.batch_transform(data.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a39857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1128, 126, 126, 12)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fingerprint.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0f649e",
   "metadata": {},
   "source": [
    "Now from these feature maps we can create the dataset suitable for training models in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeb544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "esol_fingerprint = SingleFeatureData(data.y, X_fingerprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e958d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fingerprint, val_fingerprint, test_fingerprint = random_split(esol_fingerprint, [904,112,112], generator=torch.Generator().manual_seed(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25238aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(904, 112, 112)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(val), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98528a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_fingerprint = DataLoader(train_fingerprint, batch_size=8, shuffle=True)\n",
    "val_loader_fingerprint = DataLoader(val_fingerprint, batch_size=8, shuffle=True)\n",
    "test_loader_fingerprint = DataLoader(test_fingerprint, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c5b852",
   "metadata": {},
   "source": [
    "And we can get one batch of data by making the data loader iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54b6cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t = next(iter(train_loader_fingerprint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bebca40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaf006b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 12, 126, 126])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771ea82f",
   "metadata": {},
   "source": [
    "And regression. Different feature maps have different number of channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c2e61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fingerprint = MolMapRegression(conv_in1=12)\n",
    "\n",
    "epochs = 5\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_fingerprint.to(device)\n",
    "optimizer = optim.Adam(model_fingerprint.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1b6723",
   "metadata": {},
   "source": [
    "And the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2200b504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1, Iter:    50] Training loss: 4.537\n",
      "[Epoch: 1, Iter:   100] Training loss: 3.935\n",
      "[Epoch: 2, Iter:    50] Training loss: 2.271\n",
      "[Epoch: 2, Iter:   100] Training loss: 1.954\n",
      "[Epoch: 3, Iter:    50] Training loss: 1.258\n",
      "[Epoch: 3, Iter:   100] Training loss: 1.157\n",
      "[Epoch: 4, Iter:    50] Training loss: 1.027\n",
      "[Epoch: 4, Iter:   100] Training loss: 0.880\n",
      "[Epoch: 5, Iter:    50] Training loss: 0.660\n",
      "[Epoch: 5, Iter:   100] Training loss: 0.649\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, (xb, yb) in enumerate(train_loader_fingerprint):\n",
    "\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward propagation\n",
    "        pred = model_fingerprint(xb)\n",
    "\n",
    "        # loss calculation\n",
    "        loss = criterion(pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if (i+1) % 50 == 0:    \n",
    "            print('[Epoch: %d, Iter: %5d] Training loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / (i+1)))\n",
    "\n",
    "print('Training finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d16832",
   "metadata": {},
   "source": [
    "Loss on validation data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b960b06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter:     3] Validation loss: 0.442\n",
      "[Iter:     6] Validation loss: 0.599\n",
      "[Iter:     9] Validation loss: 0.708\n",
      "[Iter:    12] Validation loss: 0.851\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for i, (xb, yb) in enumerate(val_loader_fingerprint):\n",
    "\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        # forward propagation\n",
    "        pred = model_fingerprint(xb)\n",
    "\n",
    "        # loss calculation\n",
    "        loss = criterion(pred, yb)\n",
    "        running_loss += loss.item()\n",
    "        if (i+1) % 3 == 0:    \n",
    "            print('[Iter: %5d] Validation loss: %.3f' %\n",
    "                    (i + 1, running_loss / (i+1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fc5e06",
   "metadata": {},
   "source": [
    "## Regression using both feature maps\n",
    "\n",
    "If we want to use both the feature maps, we have to process the training data differently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c38a6bc",
   "metadata": {},
   "source": [
    "Now we can feed both the feature maps to the model as a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a1ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_feature = DoubleFeatureData(data.y, (X, X_fingerprint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601b50fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_double, val_double, test_double = random_split(double_feature, [904,112,112], generator=torch.Generator().manual_seed(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89a52a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(904, 112, 112)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_double), len(val_double), len(test_double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a83e71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_double = DataLoader(train_double, batch_size=8, shuffle=True)\n",
    "val_loader_double = DataLoader(val_double, batch_size=8, shuffle=True)\n",
    "test_loader_double = DataLoader(test_double, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1b3ba1",
   "metadata": {},
   "source": [
    "And we can get one batch of data by making the data loader iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246b96df",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t = next(iter(train_loader_double))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd427cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88730ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 13, 37, 37]), torch.Size([8, 12, 126, 126]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1, x2 = x\n",
    "x1.shape, x2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d407b9",
   "metadata": {},
   "source": [
    "And regression. Different feature maps have different number of channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4b0a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_double = MolMapRegression(conv_in1=13, conv_in2=12)\n",
    "\n",
    "epochs = 5\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_double.to(device)\n",
    "optimizer = optim.Adam(model_double.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af565cc7",
   "metadata": {},
   "source": [
    "And the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d00f01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1, Iter:    50] Training loss: 6.050\n",
      "[Epoch: 1, Iter:   100] Training loss: 4.608\n",
      "[Epoch: 2, Iter:    50] Training loss: 2.854\n",
      "[Epoch: 2, Iter:   100] Training loss: 2.403\n",
      "[Epoch: 3, Iter:    50] Training loss: 1.834\n",
      "[Epoch: 3, Iter:   100] Training loss: 1.536\n",
      "[Epoch: 4, Iter:    50] Training loss: 1.027\n",
      "[Epoch: 4, Iter:   100] Training loss: 0.996\n",
      "[Epoch: 5, Iter:    50] Training loss: 0.595\n",
      "[Epoch: 5, Iter:   100] Training loss: 0.677\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, ((x1, x2), yb) in enumerate(train_loader_double):\n",
    "\n",
    "        x1, x2, yb = x1.to(device), x2.to(device), yb.to(device)\n",
    "\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward propagation\n",
    "        pred = model_double((x1, x2))\n",
    "\n",
    "        # loss calculation\n",
    "        loss = criterion(pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if (i+1) % 50 == 0:    \n",
    "            print('[Epoch: %d, Iter: %5d] Training loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / (i+1)))\n",
    "\n",
    "print('Training finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940f58be",
   "metadata": {},
   "source": [
    "Loss on validation data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cd19b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter:     3] Validation loss: 1.191\n",
      "[Iter:     6] Validation loss: 1.088\n",
      "[Iter:     9] Validation loss: 1.002\n",
      "[Iter:    12] Validation loss: 0.874\n",
      "Validation finished\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for i, ((x1, x2), yb) in enumerate(val_loader_double):\n",
    "\n",
    "        x1, x2, yb = x1.to(device), x2.to(device), yb.to(device)\n",
    "\n",
    "        # forward propagation\n",
    "        pred = model_double((x1, x2))\n",
    "\n",
    "        # loss calculation\n",
    "        loss = criterion(pred, yb)\n",
    "        running_loss += loss.item()\n",
    "        if (i+1) % 3 == 0:    \n",
    "            print('[Iter: %5d] Validation loss: %.3f' %\n",
    "                    (i + 1, running_loss / (i+1)))\n",
    "\n",
    "print('Validation finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acad28ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
